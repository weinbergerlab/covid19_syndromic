---
title: "ct_syndromic"
author: "Dan Weinberger"
date: "3/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("..")) #sets Working directory to be 1 folder up

library(reshape2)
library(lubridate)
library(INLA)
library(MMWRweek)
library(cdcfluview)
library(gtrendsR)
library(rjags)
library(HDInterval)
```

##Import and clean the data
```{r, eval=F}
ds1<-read.csv('./DO_NOT_SYNC/yale_view_2018_2019.csv')
zip.cw<-read.csv('./Data/zipcode-town.csv')

zip.cw$Zip.Code<-paste0('0',zip.cw$Zip.Code)
zip.cw[substr(zip.cw$Zip.Code,1,2) =='06',]
```

96% of entries have a CT ZIP code (06XXX)
```{r, eval=F}
ds1$classification<-toupper(ds1$classification)
ds1$ili<-grepl('ILI', ds1$classification)
ds1$cough<-grepl('COUGH', ds1$classification)
ds1$respiratory<-grepl('RESPIRATORY', ds1$classification)
ds1$circulatory<-grepl('CIRCULATORY', ds1$classification)
ds1$ili2<- grepl('FEVER/FLU', ds1$classification) 
datestr<-as.character(ds1$date_time_of_admission)
ds1$adate<-as.Date(substr(datestr,1,10))
ds1$agec<-NA
ds1$agec[ds1$age>=0  & ds1$age<5]<-1
ds1$agec[ds1$age>=5  & ds1$age<18]<-2
ds1$agec[ds1$age>=18 & ds1$age<39]<-3
ds1$agec[ds1$age>=40 & ds1$age<64]<-4
ds1$agec[ds1$age>=65 & ds1$age<110]<-5
ds1$zipcode<-as.character(ds1$zipcode)
ds1$all.visits<-1
ds2<-merge(ds1, zip.cw, by.x='zipcode', by.y='Zip.Code')

#last.date<-ds2[ds2$adate==as.Date('2020-03-09') & ds2$agec==5 & ds2$County=='Fairfield' ,c('classification'), drop=F]
```

```{r, eval=F}
ds1.m<-melt(ds2[,c('adate', 'County','agec','ili','cough','respiratory','circulatory','ili2','all.visits')], id.vars=c('adate','County','agec'))
saveRDS(ds1.m, './DO_NOT_SYNC/county_ts_ct.rds')
ds1.c<-acast(ds1.m, agec~adate ~County~variable, fun.aggregate = sum)
```

```{r}
ds1.m<-readRDS('./DO_NOT_SYNC/county_ts_ct.rds')
ds1.c<-acast(ds1.m, agec~adate ~County~variable, fun.aggregate = sum)

n.dates<-dim(ds1.c)[2]
ds1.c<-ds1.c[,-n.dates,,] #remove last time point

```

## View data
```{r}
plot(ds1.c['5',,'Fairfield','cough'], type='l')
plot(ds1.c['1',,'Fairfield','cough'], type='l')

plot(ds1.c['5',,'Fairfield','respiratory'], type='l')
plot(ds1.c['1',,'Fairfield','respiratory'], type='l')

plot(ds1.c['5',,'Fairfield','ili2'], type='l')
plot(ds1.c['5',,'Fairfield','cough']/ds1.c['5',,'Fairfield','all.visits'], type='l')

plot(ds1.c['5',,'Fairfield','cough'] / ds1.c['1',,'Fairfield','cough'], type='l')
plot(ds1.c['5',,'Fairfield','ili2'] / ds1.c['1',,'Fairfield','ili2'], type='l')


plot(ds1.c['5',,'Fairfield','respiratory']/ds1.c['1',,'Fairfield','respiratory'], type='l')

```

##Import auxillary data
Pulls in google searches for RSV in CT can get 5 years of historical data at weekly reslution (switches to monthly for >5 years)
```{r}
rsv.down<-gtrends(keyword = 'RSV', geo="US-CT", time = "today+5-y",
gprop = c("web") , category = 0,  low_search_volume = FALSE)
saveRDS(rsv.down,'./Data/rsv_searches_ct.rds')
rsv<-rsv.down$interest_over_time[,c('date','hits')]
rsv$date<-as.Date(rsv$date)
mmwr.week.rsv<-MMWRweek(rsv$date)[,c('MMWRyear','MMWRweek')]
rsv<-cbind.data.frame(rsv,mmwr.week.rsv)
names(rsv)<-c('date','rsv.searches','MMWRyear','MMWRweek')
```

flusurvnet data
https://gis.cdc.gov/GRASP/Fluview/FluHospRates.html

```{r}
flu<-read.csv('./Data/FluSurveillance_EIP_Connecticut_Data.csv', skip=2)
flu2<-flu[flu$AGE.CATEGORY %in% c('Overall'),]
#flu2$agec<-NA
#flu2$agec[flu2$AGE.CATEGORY=='0-4 yr']<-1
#flu2$agec[flu2$AGE.CATEGORY=='65+ yr']<-5
flu2<-flu2[,c('SEASON', 'MMWR.YEAR', 'MMWR.WEEK', 'WEEKLY.RATE')]
names(flu2)<-c('season', 'MMWRyear', 'MMWRweek','flu.rate')
flu2$flu.rate<-as.numeric(as.character(flu2$flu.rate))
flu2$flu.rate[is.na(flu2$flu.rate)]<-9999
```

Aggregate by week and merge auxillary variables
```{r}
ds1.m.wk<-ds1.m
ds1.m.wk$adate<-floor_date(ds1.m.wk$adate, unit='week')
ds1.df<-dcast(ds1.m.wk, agec+adate +County~variable, fun.aggregate = sum)
mmwr.date<-MMWRweek(ds1.df$adate)
ds1.df<-cbind.data.frame(ds1.df,mmwr.date)
combo2<-merge(ds1.df, flu2, by=c('MMWRyear','MMWRweek'), all.x=T)
combo2<-merge(combo2, rsv, by=c('MMWRyear','MMWRweek'), all.x=T)
combo2$flu.rate[is.na(combo2$flu.rate)]<-0
combo2$flu.rate[combo2$flu.rate==9999]<-NA #last few weeks

combo2.sub<-combo2[, c('agec', 'MMWRyear', 'MMWRweek', 'County', 'ili2','cough','respiratory','circulatory','flu.rate',"rsv.searches",'all.visits')]
ili.m<-melt(combo2.sub, id.vars=c('County','agec','MMWRyear','MMWRweek'))
ili.a<-acast(ili.m, MMWRyear+MMWRweek ~County~agec~variable , fun.aggregate = sum )
```

setup epiyear index
```{r}
date.string<-dimnames(ili.a)[[1]]
dates<-unlist(strsplit(date.string, '_'))
dates<-matrix(as.numeric(dates), ncol=2, byrow=T)
epiyr<-dates[,1]
epiyr[dates[,2]<=26] <- epiyr[dates[,2]<=26]-1
epiyr.index<-epiyr-min(epiyr)+1
```

## Evaluate results after controlling for flu and RSV
```{r}
to.test<-unique(combo2$County)

inla.func<-function(x.test, outcome.var, syndrome){
      clean.array.citywide<-ili.a[,x.test,c('1','5'),]
      epiyr.index.f<-as.factor(epiyr.index)
      epiyr.index.f2<-as.factor(epiyr.index)
      
      y.kids = t(clean.array.citywide[,'1',syndrome])
      y.adult = t(clean.array.citywide[,'5',syndrome])
              sqrt.rsv =sqrt(clean.array.citywide[,'5','rsv.searches']) #same for all ages and boroughs
                       sqrt.flu =sqrt(clean.array.citywide[,'5','flu.rate']) #same for all ages and boroughs
                       sqrt.flu[length(sqrt.flu)]<-sqrt.flu[length(sqrt.flu)-1] #fill in missing last observation
      t<-1:length(y.kids)
      t2<-1:length(y.kids)
      
      weekN<-rep(1:52, length.out=length(y.kids))
      
      ds.glm<-cbind.data.frame('weekN'=weekN,'y.kids'=y.kids[1,],'y.adult'=y.adult[1,],sqrt.rsv, sqrt.flu, t, t2)
      form1<-as.formula(paste0(outcome.var,"~ f(epiyr.index.f,sqrt.rsv, model='iid')+   #rsv effect varies by epiyr
                    f(epiyr.index.f2,sqrt.flu, model='iid') + #flu effect, varies by epiyear
                   t2+                      #linear trend   
                   f(t, model = 'iid') +    #unexplained variation..iid or ar1?
                   f(weekN, model = 'rw2', cyclic=T)" #seasonality 
                   ))
      mod1<-inla(form1, 
                 family='poisson', data=ds.glm, control.predictor = list(compute=TRUE, link = 1),control.compute=list(config=TRUE)) 
      mod1.mean.re.t<-mod1$summary.random$t$mean 
      mod1.sd.re.t<-mod1$summary.random$t$sd 
      
      out.list<-list(t.mean=mod1.mean.re.t, t.sd=mod1.sd.re.t, 'mod1'=mod1)
      return(out.list)
}
all.mods.kids<-sapply(to.test,inla.func,outcome.var='y.kids' , syndrome='ili2', simplify=F)
all.mods.adults<-sapply(to.test,inla.func,outcome.var='y.adult' ,syndrome='ili2',simplify=F)

all.mods.kids.resp<-sapply(to.test,inla.func,outcome.var='y.kids' , syndrome='respiratory', simplify=F)
all.mods.adults.resp<-sapply(to.test,inla.func,outcome.var='y.adult' ,syndrome='respiratory',simplify=F)

all.mods.kids.cough<-sapply(to.test,inla.func,outcome.var='y.kids' , syndrome='cough', simplify=F)
all.mods.adults.cough<-sapply(to.test,inla.func,outcome.var='y.adult' ,syndrome='cough',simplify=F)
```


Next extract mean and SD subtract
```{r}
inla.extract.fun<-function(adult.ds, kid.ds){
  all.mod.kid.mean<-sapply(kid.ds, '[[', "t.mean")
  all.mod.kid.sd<-sapply(kid.ds, '[[', "t.sd")
  all.mod.adult.mean<-sapply(adult.ds, '[[', "t.mean")
  all.mod.adult.sd<-sapply(adult.ds, '[[', "t.sd")
  covar1<-cov(c(all.mod.adult.mean),c(all.mod.kid.mean))
  
  #####THIS IS WHAT IS USED IN STAGE 2 
  diff.adult.kids<-all.mod.adult.mean- all.mod.kid.mean
  diff.adult.kids.var<- all.mod.adult.sd^2 +all.mod.kid.sd^2 +2*covar1
  diff.adult.kids.prec<-1/diff.adult.kids.var
  
  out.list<-list('kid.resid'=all.mod.kid.mean,'adult.resid'=all.mod.adult.mean,'diff.adult.kids'=diff.adult.kids)
  return(out.list)
  #############
}

ili.diff.adults.kids<-inla.extract.fun(adult.ds=all.mods.adults, kid.ds=all.mods.kids)
resp.diff.adults.kids<-inla.extract.fun(all.mods.adults.resp, all.mods.kids.resp)
cough.diff.adults.kids<-inla.extract.fun(all.mods.adults.cough, all.mods.kids.cough)



#matplot(all.mod.adult.mean, type='l')
#matplot(all.mod.kid.mean, type='l')

matplot(ili.diff.adults.kids$diff.adult.kids, type='l')
matplot(resp.diff.adults.kids$diff.adult.kids, type='l')
matplot(cough.diff.adults.kids$diff.adult.kids, type='l')


matplot(ili.diff.adults.kids$kid.resid, type='l')
matplot(ili.diff.adults.kids$adult.resid, type='l')


matplot(resp.diff.adults.kids$kid.resid, type='l')
matplot(resp.diff.adults.kids$adult.resid, type='l')

matplot(cough.diff.adults.kids$kid.resid, type='l')
matplot(cough.diff.adults.kids$adult.resid, type='l')

```

```{r}

#sapply(colnames(diff.adult.kids), function(x) write.csv(cbind.data.frame('diff'=diff.adult.kids[,x], 't'=1:length(diff.adult.kids[,x])) , paste0('./satscan/data/kid.v.adult.',x, '.csv') )  )
colnames(ili.diff.adults.kids$diff.adult.kids)<-as.character(to.test)
sapply(colnames(ili.diff.adults.kids$diff.adult.kids), function(x){
  ds<-cbind.data.frame('id'=1:nrow(ili.diff.adults.kids$diff.adult.kids),'one'=1,  't'=1:length(ili.diff.adults.kids$diff.adult.kids[,x]), 'diff'=ili.diff.adults.kids$diff.adult.kids[,x] )
  write.csv(ds , paste0('./satscan/data/kid.v.adult.',x, '.csv') )}  
  )

```
## NOTES FOR RUNNING SATSCAN TO DETECT CLUSTERS OF RESIDUALS
- Run a purely tmporal analysis
- Normal discrete scan statistics
- Case file is the data from 1 region, then click the advanced tab to add additional input datasets for each region
- On Input tab: time precision= Custom; study period ranging from 0 to N time points
- Analysis Tab/advanced/inference: use iterative scan statistic
- When importing data in wizard, location id can be the generated id; number of cases should be a vector of 1s, Date/time: vector from 1:N' attribute=the difference between adults and kids, as calculated above
- When importing, tick the 'save these settings and read directly' box at the end of the wizard


## As an alternative, try a space-time permutation cluster detection.
Doesn't seem to work too well due to underlying trends?. Both permutation and case-control (using kids as controls) suffer from issue with flagging overly-large clusters

```{r}
totest<-c('ili2','respiratory','cough')

satscan.fun<-function(syndrome){
coord1<-read.csv('./Data/CT_ZIPs_2010_centroids.csv')
coord1$zipcode<-paste0('0', coord1$site)

ili.ag5 <- ds2[ds2$agec==5 & ds2[,syndrome]==T,c('zipcode','adate',syndrome)]
ili.ag5<-ili.ag5[!is.na(ili.ag5$zipcode),]
ili.ag5<-merge(ili.ag5, coord1, by='zipcode') #lose ~100 cases due to missing ZIP
ili.ag5<-ili.ag5[!is.na(ili.ag5$lat),]
ili.ag5[,syndrome]<-ili.ag5[,syndrome]*1
ili.ag5<-ili.ag5[ili.ag5$adate!=max(ili.ag5$adate),] #remove last date

ili.ag1 <- ds2[ds2$agec==1 & ds2[,syndrome]==T,c('zipcode','adate',syndrome)]
ili.ag1<-ili.ag1[!is.na(ili.ag1$zipcode),]
ili.ag1<-merge(ili.ag1, coord1, by='zipcode') #lose ~100 cases due to missing ZIP
ili.ag1<-ili.ag1[!is.na(ili.ag1$lat),]
ili.ag1[,syndrome]<-ili.ag1[,syndrome]*1
ili.ag1<-ili.ag1[ili.ag1$adate !=max(ili.ag1$adate),] #remove last date

mycas = data.frame(locid=ili.ag5$zipcode,basecas=ili.ag5[,syndrome], day=ili.ag5$adate)
mycon<- data.frame(locid=ili.ag1$zipcode,basecas=ili.ag1[,syndrome], day=ili.ag1$adate)
mygeo = data.frame(locid=ili.ag5$zipcode,lat=ili.ag5$lat, long=ili.ag5$long)

#Write satscan files

td = tempdir()
write.geo(mygeo, location = td, file = "mygeo", userownames=F)
write.cas(mycas, location = td, file = "mycas")
write.cas(mycon, location = td, file = "mycon")

#write.geo(mygeo, location = './satscan/data/', file = "geo.spacetime.ct", userownames=F)
#write.cas(mycas, location = './satscan/data/', file = "ili.spacetime")

#Parameter files

first.date<-as.character(min(mycas$day))
first.date<-gsub('-', '/',first.date)
last.date<-as.character(max(mycas$day))
last.date<-gsub('-', '/',last.date)
invisible(ss.options(reset=TRUE))
ss.options(list(CaseFile="mycas.cas", ControlFile="mycon.cas", PrecisionCaseTimes=3))
ss.options(list(StartDate=first.date, CoordinatesType=1, TimeAggregationUnits=3,TimeAggregationLength=1))
ss.options(list(EndDate=last.date, CoordinatesFile="mygeo.geo", AnalysisType=4, ModelType=1)) 
ss.options(list(ProspectiveStartDate="2020/01/01", ReportGiniClusters="n", LogRunToHistoryFile="n"))

write.ss.prm(td, "mybase")
#write.ss.prm('./satscan/satscan parameters', "spacetime")

mybase = satscan(td, "mybase")
return(mybase)
}

satscan.res<-lapply(totest, satscan.fun)

summary(satscan.res[[1]])
```





