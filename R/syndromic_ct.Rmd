---
title: "ct_syndromic"
author: "Dan Weinberger"
date: "3/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set(root.dir = normalizePath("..")) #sets Working directory to be 1 folder up

library(reshape2)
library(lubridate)
library(INLA)
library(MMWRweek)
library(cdcfluview)
library(gtrendsR)
library(rjags)
library(HDInterval)
library(shiny)
library(pbapply)
library(zoo)
```

##Import and clean the data
```{r, eval=F}
ds1<-read.csv('../DO_NOT_SYNC/yale_view_2018_2019.csv')
zip.cw<-read.csv('../Data/zipcode-town.csv')

zip.cw$Zip.Code<-paste0('0',zip.cw$Zip.Code)
zip.cw[substr(zip.cw$Zip.Code,1,2) =='06',]
```

96% of entries have a CT ZIP code (06XXX)
```{r, eval=F}
ds1$classification<-toupper(ds1$classification)
ds1$ili<-grepl('ILI', ds1$classification)
ds1$cough<-grepl('COUGH', ds1$classification)
ds1$respiratory<-grepl('RESPIRATORY', ds1$classification)
ds1$circulatory<-grepl('CIRCULATORY', ds1$classification)
ds1$ili2<- grepl('FEVER/FLU', ds1$classification) 
datestr<-as.character(ds1$date_time_of_admission)
ds1$adate<-as.Date(substr(datestr,1,10))
ds1$agec<-NA
ds1$agec[ds1$age>=0  & ds1$age<5]<-1
ds1$agec[ds1$age>=5  & ds1$age<18]<-2
ds1$agec[ds1$age>=18 & ds1$age<39]<-3
ds1$agec[ds1$age>=40 & ds1$age<64]<-4
ds1$agec[ds1$age>=65 & ds1$age<110]<-5
ds1$zipcode<-as.character(ds1$zipcode)
ds1$all.visits<-1
ds2<-merge(ds1, zip.cw, by.x='zipcode', by.y='Zip.Code')

#last.date<-ds2[ds2$adate==as.Date('2020-03-09') & ds2$agec==5 & ds2$County=='Fairfield' ,c('classification'), drop=F]
```

```{r, eval=F}
ds1.m<-melt(ds2[,c('adate', 'County','agec','ili','cough','respiratory','circulatory','ili2','all.visits')], id.vars=c('adate','County','agec'))
saveRDS(ds1.m, '../DO_NOT_SYNC/county_ts_ct.rds')
ds1.c<-acast(ds1.m, agec~adate ~County~variable, fun.aggregate = sum)
```

```{r}
ds1.m<-readRDS('../DO_NOT_SYNC/county_ts_ct.rds')
ds1.c<-acast(ds1.m, agec~adate ~County~variable, fun.aggregate = sum)

n.dates<-dim(ds1.c)[2]
ds1.c<-ds1.c[,-n.dates,,] #remove last time point
saveRDS(ds1.c,'./private_data/shiny_data.rds') #save data for the shiny app

```

## View data
```{r}
counties<-dimnames(ds1.c)[[3]]
ages<-dimnames(ds1.c)[[1]]
#syndromes<- dimnames(ds1.c)[[4]]
syndromes<-'ili2'
for(j in syndromes){
for(i in counties){
par(mfrow=c(2,3))  
for(k in ages){
  plot(ds1.c[k,,i,j]/ds1.c[k,,i,'all.visits'], type='l', bty='l', main=paste(j,i,k))
  }
 }
}


```




##Import auxillary data
Pulls in google searches for RSV in CT can get 5 years of historical data at weekly reslution (switches to monthly for >5 years)
```{r}
rsv.down<-gtrends(keyword = 'RSV', geo="US-CT", time = "today+5-y",
gprop = c("web") , category = 0,  low_search_volume = FALSE)
saveRDS(rsv.down,'../Data/rsv_searches_ct.rds')
rsv<-rsv.down$interest_over_time[,c('date','hits')]
rsv$date<-as.Date(rsv$date)
mmwr.week.rsv<-MMWRweek(rsv$date)[,c('MMWRyear','MMWRweek')]
rsv<-cbind.data.frame(rsv,mmwr.week.rsv)
names(rsv)<-c('date','rsv.searches','MMWRyear','MMWRweek')
```

flusurvnet data
https://gis.cdc.gov/GRASP/Fluview/FluHospRates.html

```{r}
flu<-read.csv('../Data/FluSurveillance_EIP_Connecticut_Data.csv', skip=2)
flu2<-flu[flu$AGE.CATEGORY %in% c('Overall'),]
#flu2$agec<-NA
#flu2$agec[flu2$AGE.CATEGORY=='0-4 yr']<-1
#flu2$agec[flu2$AGE.CATEGORY=='65+ yr']<-5
flu2<-flu2[,c('SEASON', 'MMWR.YEAR', 'MMWR.WEEK', 'WEEKLY.RATE')]
names(flu2)<-c('season', 'MMWRyear', 'MMWRweek','flu.rate')
flu2$flu.rate<-as.numeric(as.character(flu2$flu.rate))
flu2$flu.rate[is.na(flu2$flu.rate)]<-9999
```

Aggregate by week and merge auxillary variables
```{r}
ds1.m.wk<-ds1.m
#ds1.m.wk$adate<-floor_date(ds1.m.wk$adate, unit='week')
ds1.m.wk$adate<-ds1.m.wk$adate
ds1.df<-dcast(ds1.m.wk, agec+adate +County~variable, fun.aggregate = sum)
mmwr.date<-MMWRweek(ds1.df$adate)
ds1.df<-cbind.data.frame(ds1.df,mmwr.date)
combo2<-merge(ds1.df, flu2, by=c('MMWRyear','MMWRweek'), all.x=T)
combo2<-merge(combo2, rsv, by=c('MMWRyear','MMWRweek'), all.x=T)
combo2$flu.rate[is.na(combo2$flu.rate)]<-0
combo2$flu.rate[combo2$flu.rate==9999]<-NA #last few weeks

combo2.sub<-combo2[, c('agec', 'adate','MMWRyear', 'MMWRweek', 'County', 'ili2','cough','respiratory','circulatory','flu.rate',"rsv.searches",'all.visits')]
ili.m<-melt(combo2.sub, id.vars=c('County','agec','adate','MMWRyear','MMWRweek'))
ili.a<-acast(ili.m, adate+MMWRyear+MMWRweek ~County~agec~variable , fun.aggregate = sum )
dimnames(ili.a)[[1]]<-substr(dimnames(ili.a)[[1]],1,10)
```

setup epiyear index
```{r}
date.string<-as.Date(dimnames(ili.a)[[1]])
month<-month(date.string)
epiyr<-year(date.string)
epiyr[month<=6] <- epiyr[month<=6]-1
epiyr.index<-epiyr-min(epiyr)+1
weekN<-MMWRweek(date.string)[,'MMWRweek']
day.of.year<-yday(date.string)
```

## Evaluate results after controlling for flu and RSV
```{r}
counties.to.test<-unique(combo2$County)

gam.func<-function(x.test, age.test, syndrome){
clean.array.citywide<-ili.a[,x.test,,]
      epiyr.index.f<-as.factor(epiyr.index)
      epiyr.index.f2<-as.factor(epiyr.index)
      
      y.age = t(clean.array.citywide[,age.test,syndrome])
     
            sqrt.rsv =sqrt(clean.array.citywide[,'5','rsv.searches']) #same for all ages and boroughs
            sqrt.flu =sqrt(clean.array.citywide[,'5','flu.rate']) #same for all ages and boroughs
            
            
            sqrt.flu<- na.locf(sqrt.flu)  #fill in missing observations for flu at end of TS with most recent observed values
      t2<-1:length(y.age)
      

      ds.glm<-cbind.data.frame('day.of.year'=day.of.year,'y.age'=y.age[1,],sqrt.rsv, sqrt.flu,  t2,epiyr.index.f)
      form1<-as.formula(paste0('y.age',"~ epiyr.index.f*sqrt.rsv +   #rsv effect varies by epiyr
                   epiyr.index.f*sqrt.flu + #flu effect, varies by epiyear
                   t2+                      #linear trend   
                   s(day.of.year, bs='cc')" #seasonality 
                   ))
      mod1<-gam(form1, 
                 family='poisson', data=ds.glm) 
    pred1<-predict(mod1, type='response', newdata = ds.glm)
    resid1<-y.age[1,]/pred1
      
      out.list<-list(y=y.age[1,], pred=pred1, resid1=resid1)
      return(out.list)
}


syndromes<- c('ili2', 'respiratory','cough') 
ages <-   c('1','2','3','4','5')

all.gam.res<- pblapply(syndromes, function(x){
  ww<- lapply(ages, function(y){
    lapply(counties.to.test, gam.func, age.test=y, syndrome=x)
  }
  ) 
  names(ww)<- ages
  return(ww)
  }
)
names(all.gam.res)<-syndromes

```


Next extract residuals and fitted values
```{r, fig.width=8, fig.height=12}

#Residuals for all age groups for ILI
ili2.resid<- sapply(all.gam.res[['ili2']], function(x) sapply(x,'[[','resid1'), simplify='array')
ili2.pred<- sapply(all.gam.res[['ili2']], function(x) sapply(x,'[[','pred'), simplify='array')
obs<- sapply(all.gam.res[['ili2']], function(x) sapply(x,'[[','y'), simplify='array')

ili.diff.adults.kids<-ili2.resid

par(mfrow=c(2,3), mar=c(3,2,1,1))
for(i in 1:5){
  matplot(ili2.resid[1,,i], type='l', bty='l', ylab='Residual')
}

par(mfrow=c(2,3), mar=c(3,2,1,1))
for(i in 1:5){
  matplot(obs[,,i], pch=16, bty='l', ylab='Fitted')
  matplot(ili2.pred[,,i], type='l', bty='l', ylab='Fitted', add=T)
}


par(mfrow=c(5,1), mar=c(3,2,1,1))
for(i in 1:5){
  plot(obs[,1,i], type='l', bty='l', ylab='Fitted')
  points(ili2.pred[,1,i], type='l', col='red' )
}




```

```{r}

#sapply(colnames(diff.adult.kids), function(x) write.csv(cbind.data.frame('diff'=diff.adult.kids[,x], 't'=1:length(diff.adult.kids[,x])) , paste0('../satscan/data/kid.v.adult.',x, '.csv') )  )
colnames(ili.diff.adults.kids$diff.adult.kids)<-as.character(to.test)
sapply(colnames(ili.diff.adults.kids$diff.adult.kids), function(x){
  ds<-cbind.data.frame('id'=1:nrow(ili.diff.adults.kids$diff.adult.kids),'one'=1,  't'=1:length(ili.diff.adults.kids$diff.adult.kids[,x]), 'diff'=ili.diff.adults.kids$diff.adult.kids[,x] )
  write.csv(ds , paste0('../satscan/data/kid.v.adult.',x, '.csv') )}  
  )

```
## NOTES FOR RUNNING SATSCAN TO DETECT CLUSTERS OF RESIDUALS
- Run a purely tmporal analysis
- Normal discrete scan statistics
- Case file is the data from 1 region, then click the advanced tab to add additional input datasets for each region
- On Input tab: time precision= Custom; study period ranging from 0 to N time points
- Analysis Tab/advanced/inference: use iterative scan statistic
- When importing data in wizard, location id can be the generated id; number of cases should be a vector of 1s, Date/time: vector from 1:N' attribute=the difference between adults and kids, as calculated above
- When importing, tick the 'save these settings and read directly' box at the end of the wizard


## As an alternative, try a space-time permutation cluster detection.
Doesn't seem to work too well due to underlying trends?. Both permutation and case-control (using kids as controls) suffer from issue with flagging overly-large clusters

```{r}
totest<-c('ili2','respiratory','cough')

satscan.fun<-function(syndrome){
coord1<-read.csv('../Data/CT_ZIPs_2010_centroids.csv')
coord1$zipcode<-paste0('0', coord1$site)

ili.ag5 <- ds2[ds2$agec==5 & ds2[,syndrome]==T,c('zipcode','adate',syndrome)]
ili.ag5<-ili.ag5[!is.na(ili.ag5$zipcode),]
ili.ag5<-merge(ili.ag5, coord1, by='zipcode') #lose ~100 cases due to missing ZIP
ili.ag5<-ili.ag5[!is.na(ili.ag5$lat),]
ili.ag5[,syndrome]<-ili.ag5[,syndrome]*1
ili.ag5<-ili.ag5[ili.ag5$adate!=max(ili.ag5$adate),] #remove last date

ili.ag1 <- ds2[ds2$agec==1 & ds2[,syndrome]==T,c('zipcode','adate',syndrome)]
ili.ag1<-ili.ag1[!is.na(ili.ag1$zipcode),]
ili.ag1<-merge(ili.ag1, coord1, by='zipcode') #lose ~100 cases due to missing ZIP
ili.ag1<-ili.ag1[!is.na(ili.ag1$lat),]
ili.ag1[,syndrome]<-ili.ag1[,syndrome]*1
ili.ag1<-ili.ag1[ili.ag1$adate !=max(ili.ag1$adate),] #remove last date

mycas = data.frame(locid=ili.ag5$zipcode,basecas=ili.ag5[,syndrome], day=ili.ag5$adate)
mycon<- data.frame(locid=ili.ag1$zipcode,basecas=ili.ag1[,syndrome], day=ili.ag1$adate)
mygeo = data.frame(locid=ili.ag5$zipcode,lat=ili.ag5$lat, long=ili.ag5$long)

#Write satscan files

td = tempdir()
write.geo(mygeo, location = td, file = "mygeo", userownames=F)
write.cas(mycas, location = td, file = "mycas")
write.cas(mycon, location = td, file = "mycon")

#write.geo(mygeo, location = '../satscan/data/', file = "geo.spacetime.ct", userownames=F)
#write.cas(mycas, location = '../satscan/data/', file = "ili.spacetime")

#Parameter files

first.date<-as.character(min(mycas$day))
first.date<-gsub('-', '/',first.date)
last.date<-as.character(max(mycas$day))
last.date<-gsub('-', '/',last.date)
invisible(ss.options(reset=TRUE))
ss.options(list(CaseFile="mycas.cas", ControlFile="mycon.cas", PrecisionCaseTimes=3))
ss.options(list(StartDate=first.date, CoordinatesType=1, TimeAggregationUnits=3,TimeAggregationLength=1))
ss.options(list(EndDate=last.date, CoordinatesFile="mygeo.geo", AnalysisType=4, ModelType=1)) 
ss.options(list(ProspectiveStartDate="2020/01/01", ReportGiniClusters="n", LogRunToHistoryFile="n"))

write.ss.prm(td, "mybase")
#write.ss.prm('../satscan/satscan parameters', "spacetime")

mybase = satscan(td, "mybase")
return(mybase)
}

satscan.res<-lapply(totest, satscan.fun)

summary(satscan.res[[1]])
```


