---
title: "covid_19_syndromic"
author: "Dan Weinberger"
date: "3/8/2020"
output: html_document
---

The goal of these analyses is to detect increases in syndromic disease activity associated with  COVID-19. As a test, we are using syndromic disease data from New York City. Data are stratified by day, borrough, age group. the data were downloaded from the [Epiquery website](https://a816-health.nyc.gov/hdi/epiquery/visualizations?PageType=ps&PopulationSource=Syndromic)

The approach is:
1) Create weekly time series for ILI, respiratory, etc
2) Get flu activity data from EIP for Albany (download online)
3) Get RSV activity data for NYC from Google trends (we have done some validation of this..)
4) Fit a regression model where the outcome is ILI (or other syndrome), and we adjust for flu, RSV, and seasonality. This is done separately for <5 year olds and 65+ year old and for each of the 5 boroughs
5) Extract residuals from the model. This tells us how much unexplained variability is in the data in each week. We could stop here and look for unusual activity. or we can continue on to step 6
6) Take the difference of the residuals for 65+ year olds and <5 year olds. 
7) Use SATSCAN to detect temporal clusters in the residuals from steps 5 or the difference in residuals from 6. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath("..")) #sets Working directory to be 1 folder up

library(reshape2)
library(lubridate)
library(INLA)
library(MMWRweek)
library(cdcfluview)
library(gtrendsR)
library(mgcv)
library(rjags)
library(HDInterval)
library(rsatscan)
```

## Read in the data

Import the data and remove the unnecesary rows. Note that the file downloads as a .csv format, but it is actually a tab-separated file.

This pulls in the ILI syndromic data from Epiquery in NYC
```{r, eval=F}
ili1<- read.table('./Data/ILI_2020_3_8.csv',sep="\t", header=TRUE, skipNul = T) 
resp1<-read.table('./Data/resp_2020_3_8.csv',sep="\t", header=TRUE, skipNul = T) 
combo1<-rbind.data.frame(ili1, resp1)

names(combo1)<-c('note','syndrome','geo.level','borough','ag.level','age_group','date','metric', 'count')

combo1<-combo1[,c('syndrome','borough','age_group','date','count')]
combo1$date<-as.Date(combo1$date, '%m/%d/%y')
mmwr.week<-MMWRweek(combo1$date)
combo1<-cbind.data.frame(combo1, mmwr.week)
combo1$count<-gsub(',', '', combo1$count) #remove commas from number
combo1$count<-as.numeric(as.character(combo1$count))

saveRDS(combo1,'./Data/ili_resp.rds')
```


```{r}
combo1<-readRDS('./Data/ili_resp.rds')
```

Pull in the EIP flu data  from https://gis.cdc.gov/GRASP/Fluview/FluHospRates.html
```{r}
flu<-read.csv('./Data/FluSurveillance_EIP_New York - Albany_Data.csv', skip=2)
```

This pulls in the NREVSS syndromic data from CDC (not currently being used)
```{r}
#nrevss<-who_nrevss(region=c('state'))
#clin.ny<-nrevss$clinical_labs
#clin.ny<-clin.ny[clin.ny$region=='New York',]
#clin.ny$percent_positive<-as.numeric(clin.ny$percent_positive)
#clin.ny$wk_date<-NULL
#clin.ny[,-c(1:2)]<-apply(clin.ny[,-c(1:2)],2, function(x) as.numeric(x))
#flu<-clin.ny
#ph.ny<-nrevss$public_health_labs
#ph.ny<-ph.ny[ph.ny$region=='New York',]
```

Pulls in google searches for RSV in NYC. can get 5 years of historical data at weekly reslution (switches to monthly for >5 years)
```{r}
rsv.down<-gtrends(keyword = 'RSV', geo="US-NY-501", time = "today+5-y",
gprop = c("web") , category = 0,  low_search_volume = FALSE)
saveRDS(rsv.down,'./Data/rsv_searches_nyc.rds')
rsv<-rsv.down$interest_over_time[,c('date','hits')]
rsv$date<-as.Date(rsv$date)
mmwr.week.rsv<-MMWRweek(rsv$date)[,c('MMWRyear','MMWRweek')]
rsv<-cbind.data.frame(rsv,mmwr.week.rsv)
names(rsv)<-c('date','rsv.searches','MMWRyear','MMWRweek')
```


```{r}
#select.syndrome<-"Respiratory"
select.syndrome<-"Influenza-like illness (ILI)"
```

## Reshape the ILI data 
Aggregate by MMWR date. For now, just focus on ILI
```{r}
combo1$MMWRday<-NULL
combo1$date<-NULL

combo1.m<-melt(combo1[combo1$syndrome==select.syndrome,], id.vars=c('syndrome', 'borough','age_group','MMWRyear','MMWRweek'))
combo1.a<-dcast(combo1.m, MMWRyear+MMWRweek +borough+syndrome~age_group, fun.aggregate = sum )
combo1.a$"o65"<-combo1.a$`Ages 65+ years`
combo1.a$"u5"<-combo1.a$`Ages 0-4 years`
combo1.a$epiyr<-combo1.a$MMWRyear
combo1.a$epiyr[combo1.a$MMWRweek<=26] <-combo1.a$epiyr[combo1.a$MMWRweek<=26] -1
combo1.a$date.index<- combo1.a$MMWRyear +combo1.a$MMWRweek/52-1/52
```

## Explore the city-wide data from NYC
```{r}
nyc<-combo1.a[combo1.a$borough=='Citywide',]
#nyc<-combo1.a[combo1.a$borough=='Manhattan',]

```

```{r}
plot(nyc$date.index,nyc$"Ages 18-64 years", type='l', bty='l', main='ILI all ages in NYC')
```

```{r, fig.width=4, fig.height=6}
par(mfrow=c(2,1), mar=c(2,2,2,1))
plot(nyc$date.index,nyc$`Ages 0-4 years`, type='l', bty='l', main='ILI <5 years in NYC')
plot(nyc$date.index,nyc$`Ages 65+ years`, type='l', bty='l', main='ILI 65+ years in NYC')
```

Plot ratio of 65+ to younger age groups for ILI
```{r, fig.width=12, fig.height=4}
ages<-c("Ages 0-4 years", "Ages 5-17 years",  "Ages 18-64 years" )
plot.rat<-function(age.select){
nyc$age.rat<-(nyc$`Ages 65+ years`+0.5)/(nyc[,age.select]+0.5)
plot(nyc$date.index,log(nyc$age.rat), type='l', bty='l', main=paste0('ratio of 65+ and ',age.select), yaxt='n', ylab='Ratio')
axis(side=2, at=-c(-5, -0.5, 0, 0.5), label=round(exp(c(-5, -0.5, 0, 0.5)),2) )
}
par(mfrow=c(1,3))
lapply(ages, plot.rat)
```



Disaggregated boroughs data. 
```{r}
bur1<- combo1.a[combo1.a$borough != 'Citywide',]
bur1$borough<-factor(bur1$borough)
```



## Prepare data for JAGS
Create a 4D array with all of the data

```{r}
ili<-combo1[combo1$syndrome==select.syndrome & combo1$age_group %in% c('Ages 0-4 years','Ages 65+ years'),  c('age_group','syndrome', 'borough','MMWRyear','MMWRweek','count')]
names(ili)<-c('age_group','syndrome', 'borough','MMWRyear','MMWRweek','ili')
ili$agec<-NA
ili$agec[ili$age_group=='Ages 0-4 years']<-1
ili$agec[ili$age_group=='Ages 65+ years']<-5
```

Use overall aggregate flu hospitalizations
```{r}
flu2<-flu[flu$AGE.CATEGORY %in% c('Overall'),]
#flu2$agec<-NA
#flu2$agec[flu2$AGE.CATEGORY=='0-4 yr']<-1
#flu2$agec[flu2$AGE.CATEGORY=='65+ yr']<-5
flu2<-flu2[,c('SEASON', 'MMWR.YEAR', 'MMWR.WEEK', 'WEEKLY.RATE')]
names(flu2)<-c('season', 'MMWRyear', 'MMWRweek','flu.rate')
flu2$flu.rate<-as.numeric(as.character(flu2$flu.rate))
flu2$flu.rate[is.na(flu2$flu.rate)]<-9999

```

```{r}
combo2<-merge(ili, flu2, by=c('MMWRyear','MMWRweek'), all.x=T)
combo2<-merge(combo2, rsv, by=c('MMWRyear','MMWRweek'), all.x=T)
combo2$flu.rate[is.na(combo2$flu.rate)]<-0
combo2$flu.rate[combo2$flu.rate==9999]<-NA #last few weeks
```


```{r}
combo2.sub<-combo2[, c('agec', 'MMWRyear', 'MMWRweek', 'borough', 'ili','flu.rate',"rsv.searches")]
ili.m<-melt(combo2.sub, id.vars=c('borough','agec','MMWRyear','MMWRweek'))
ili.a<-acast(ili.m, MMWRyear+MMWRweek ~borough~agec~variable , fun.aggregate = sum )
clean.array.jags<-ili.a[,c('Bronx','Brooklyn','Manhattan','Queens' ,'Staten Island'),c('1','5'),]
clean.array.jags[216,,,"flu.rate"]<-clean.array.jags[215,,,"flu.rate"] #patch for now to deal with missing last week of 
saveRDS(clean.array.jags,'./Data/jags.ds.rds')
```

```{r}
plot(scale(ili.a[,'Citywide','1','ili']), col='blue')
points(scale(ili.a[,'Citywide','1','flu.rate']), col='red')
points(scale(ili.a[,'Citywide','1','rsv.searches']), col='gray')

#Cross correlation
ccf(ili.a[,'Citywide','1','ili'], ili.a[,'Citywide','1',"rsv.searches"], na.action=na.omit)
```


## simple gam with citywide data to test
```{r}
clean.array.citywide<-ili.a[,c('Citywide'),c('1','5'),]

y.kids = t(clean.array.citywide[,'1','ili'])
y.adult = t(clean.array.citywide[,'5','ili'])
        sqrt.rsv =sqrt(clean.array.citywide[,'5','rsv.searches']) #same for all ages and boroughs
                 sqrt.flu =sqrt(clean.array.citywide[,'5','flu.rate']) #same for all ages and boroughs
                 sqrt.flu[216]<-sqrt.flu[215]
t<-1:length(y.kids)
weekN<-rep(1:52, length.out=length(y.kids))

ds.glm<-cbind.data.frame('weekN'=weekN,'y.kids'=y.kids[1,],'y.adult'=y.adult[1,],sqrt.rsv, sqrt.flu, t)
mod1<-gam(y.adult~ sqrt.rsv+sqrt.flu +s(t,bs='bs') +s(weekN, bs='cc') , family='poisson', data=ds.glm)
  plot(mod1) 
pp1 <- predict(mod1, type = "terms")

mod2<-gam(y.kids~ sqrt.rsv+sqrt.flu +s(t, bs='bs') +s(weekN, bs='cc') , family='poisson', data=ds.glm)
  plot(mod2) 
pp2 <- predict(mod2, type = "terms")

diff1_2<- (pp2[,'s(t)']+ pp2[,'s(weekN)']) -(pp1[,'s(t)'] + + pp2[,'s(weekN)'])
  plot(diff1_2)
  
 # jagmod1<-jagam(y.adult~ s(weekN, bs='cc', k=15), family='poisson', data=ds.glm, file='./R/jags.test.txt')
#  S1<-jagmod1$jags.data$S1
 # zero<-jagmod1$jags.data$zero

```

setup epiyear index
```{r}
date.string<-dimnames(ili.a)[[1]]
dates<-unlist(strsplit(date.string, '_'))
dates<-matrix(as.numeric(dates), ncol=2, byrow=T)
epiyr<-dates[,1]
epiyr[dates[,2]<=26] <- epiyr[dates[,2]<=26]-1
epiyr.index<-epiyr-min(epiyr)+1
```


## Stage 1 model: 
Estimate variation in ILI that is not associated with RSv or flu. Simple poisson model where we have covariates for flu and RSV (with coefficients varying by year). QUESTION FOR JOSH: Should we use IID or rw2(spline) to capture the unexplained piece. rw2 seems to give a more plausible picture of residual variation, while 
use INLA for stage 1
```{r}
to.test<-c('Bronx','Brooklyn','Manhattan','Queens' ,'Staten Island')
inla.func<-function(x.test, outcome.var){
clean.array.citywide<-ili.a[,x.test,c('1','5'),]
epiyr.index.f<-as.factor(epiyr.index)
epiyr.index.f2<-as.factor(epiyr.index)

y.kids = t(clean.array.citywide[,'1','ili'])
y.adult = t(clean.array.citywide[,'5','ili'])
        sqrt.rsv =sqrt(clean.array.citywide[,'5','rsv.searches']) #same for all ages and boroughs
                 sqrt.flu =sqrt(clean.array.citywide[,'5','flu.rate']) #same for all ages and boroughs
                 sqrt.flu[length(sqrt.flu)]<-sqrt.flu[length(sqrt.flu)-1] #fill in missing last observation
t<-1:length(y.kids)
t2<-1:length(y.kids)

weekN<-rep(1:52, length.out=length(y.kids))

ds.glm<-cbind.data.frame('weekN'=weekN,'y.kids'=y.kids[1,],'y.adult'=y.adult[1,],sqrt.rsv, sqrt.flu, t, t2)
form1<-as.formula(paste0(outcome.var,"~ f(epiyr.index.f,sqrt.rsv, model='iid')+   #rsv effect varies by epiyr
              f(epiyr.index.f2,sqrt.flu, model='iid') + #flu effect, varies by epiyear
             t2+                      #linear trend   
             f(t, model = 'iid') +    #unexplained variation..iid or ar1?
             f(weekN, model = 'rw2', cyclic=T)" #seasonality 
             ))
mod1<-inla(form1, 
           family='poisson', data=ds.glm, control.predictor = list(compute=TRUE, link = 1),control.compute=list(config=TRUE)) 
# resamp<-inla.posterior.sample(n=500,mod1,seed=123)
# resamp2<-sapply(resamp, '[[', 'latent')
# labs<-dimnames(resamp[[1]]$latent)[[1]]
# resamp2<-resamp2[grep('t:', labs, fixed=T),]
# resamp2.mean<-apply(resamp2,1,mean) #why doesn't this match below? seems to have underlying trend in there

mod1.mean.re.t<-mod1$summary.random$t$mean 
#mod1.median.re.t<-mod1$summary.random$t$`0.5quant` 

mod1.sd.re.t<-mod1$summary.random$t$sd 

out.list<-list(t.mean=mod1.mean.re.t, t.sd=mod1.sd.re.t, 'mod1'=mod1)
return(out.list)
}
all.mods.kids<-sapply(to.test,inla.func,outcome.var='y.kids' ,simplify=F)
all.mods.adults<-sapply(to.test,inla.func,outcome.var='y.adult' ,simplify=F)
```

Next extract mean and SD subtract
```{r}
all.mod.kid.mean<-sapply(all.mods.kids, '[[', "t.mean")
all.mod.kid.sd<-sapply(all.mods.kids, '[[', "t.sd")
all.mod.adult.mean<-sapply(all.mods.adults, '[[', "t.mean")
all.mod.adult.sd<-sapply(all.mods.adults, '[[', "t.sd")
covar1<-cov(c(all.mod.adult.mean),c(all.mod.kid.mean))

#####THIS IS WHAT IS USED IN STAGE 2 
diff.adult.kids<-all.mod.adult.mean- all.mod.kid.mean
diff.adult.kids.var<- all.mod.adult.sd^2 +all.mod.kid.sd^2 +2*covar1
diff.adult.kids.prec<-1/diff.adult.kids.var
#############

matplot(all.mod.adult.mean, type='l')
matplot(all.mod.kid.mean, type='l')

matplot(diff.adult.kids, type='l')


```
compare to scaled data
```{r}
scale.ili<-apply(clean.array.jags[,,'5','ili'],2,scale)
matplot(scale.ili, type='l')
```


## Format for SATSCAN temporal analysis
```{r}

#sapply(colnames(diff.adult.kids), function(x) write.csv(cbind.data.frame('diff'=diff.adult.kids[,x], 't'=1:length(diff.adult.kids[,x])) , paste0('./satscan/data/kid.v.adult.',x, '.csv') )  )

sapply(colnames(diff.adult.kids), function(x){
  ds<-cbind.data.frame('id'=1:nrow(diff.adult.kids),'one'=1,  't'=1:length(diff.adult.kids[,x]), 'diff'=diff.adult.kids[,x] )
  write.csv(ds , paste0('./satscan/data/kid.v.adult.',x, '.csv') )}  
  )

```

## NOTES FOR RUNNING SATSCAN
- Run a purely temporal analysis
- Normal discrete scan statistics
- Case file is the data from 1 region, then click the advanced tab to add additional input datasets for each region
- On Input tab: time precision= Custom; study period ranging from 0 to N time points
- Analysis Tab/advanced/inference: use iterative scan statistic
- When importing data in wizard, location id can be the generated id; number of cases should be a vector of 1s, Date/time: vector from 1:N' attribute=the difference between adults and kids, as calculated above
- When importing, tick the 'save these settings and read directly' box at the end of the wizard



